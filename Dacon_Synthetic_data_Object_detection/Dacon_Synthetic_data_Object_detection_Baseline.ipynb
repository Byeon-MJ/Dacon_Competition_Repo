{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyN9y4ofg4YZR1qei1HMqGHo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Byeon-MJ/Dacon_Repo/blob/main/Dacon_Synthetic_data_Object_detection/Dacon_Synthetic_data_Object_detection_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Synthetic data Object detection Baseline Code\n",
        "https://dacon.io/competitions/official/236107/overview/description\n",
        "\n",
        "Use Pytorch & Faster-RCNN"
      ],
      "metadata": {
        "id": "8Xdx9jfdEACM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "sxt5hS3CDtIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "metadata": {
        "id": "FXr8rzi0D3qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "7afUYAdqEQbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV0aa065Eja8",
        "outputId": "0bba6837-a199-41e6-afd3-b94ffe5536fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Setting"
      ],
      "metadata": {
        "id": "pWN9Hhc4FPJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CFG = {\n",
        "    'NUM_CLASS':34,\n",
        "    'IMG_SIZE':512,\n",
        "    'EPOCHS':10,\n",
        "    'LR':3e-4,\n",
        "    'BATCH_SIZE':32,\n",
        "    'SEED':41\n",
        "}"
      ],
      "metadata": {
        "id": "jTOKC2pvb_Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixed Random-Seed"
      ],
      "metadata": {
        "id": "8-UfWnMzcFhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "lPusA5c0cmdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything(CFG['SEED'])"
      ],
      "metadata": {
        "id": "X0BtnJwWc2MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "oBZJJfAMc9wH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_boxes_on_image(image_path, annotation_path):\n",
        "    # 이미지 불러오기\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # txt 파일에서 Class ID와 Bounding Box 정보 읽기\n",
        "    with open(annotation_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        values = list(map(float, line.strip().split(' ')))\n",
        "        class_id = int(values[0])\n",
        "        x_min, y_min = int(round(values[1])), int(round(values[2]))\n",
        "        x_max, y_max = int(round(max(values[3], values[5], values[7]))), int(round(max(values[4], values[6], values[8])))\n",
        "\n",
        "        # 이미지에 바운딩 박스 그리기\n",
        "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)\n",
        "        cv2.putText(image, str(class_id), (x_min, y_min - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "    # 이미지와 바운딩 박스 출력\n",
        "    plt.figure(figsize=(25, 25))\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vXTThGn4dAVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 경로 설정\n",
        "image_file = './train/syn_00001.png'\n",
        "annotation_file = './train/syn_00001.txt'"
      ],
      "metadata": {
        "id": "k9-xofA3f3xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 함수 실행\n",
        "draw_boxes_on_image(image_file, annotation_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "mFoS6F9Yf_7o",
        "outputId": "072e94d8-c13a-4010-d07a-66bd948efd03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-852dff6d34af>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 함수 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdraw_boxes_on_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-1273c99dd03c>\u001b[0m in \u001b[0;36mdraw_boxes_on_image\u001b[0;34m(image_path, annotation_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# 이미지 불러오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# txt 파일에서 Class ID와 Bounding Box 정보 읽기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EjkNGTdQgE0A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}