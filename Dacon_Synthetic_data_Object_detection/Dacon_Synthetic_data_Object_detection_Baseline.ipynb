{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNu3HDqgZxA2IkK4geyUfVa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Byeon-MJ/Dacon_Repo/blob/main/Dacon_Synthetic_data_Object_detection/Dacon_Synthetic_data_Object_detection_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Synthetic data Object detection Baseline Code\n",
        "https://dacon.io/competitions/official/236107/overview/description\n",
        "\n",
        "Use Pytorch & Faster-RCNN"
      ],
      "metadata": {
        "id": "8Xdx9jfdEACM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "sxt5hS3CDtIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "metadata": {
        "id": "FXr8rzi0D3qw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "7afUYAdqEQbR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV0aa065Eja8",
        "outputId": "0bba6837-a199-41e6-afd3-b94ffe5536fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Setting"
      ],
      "metadata": {
        "id": "pWN9Hhc4FPJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CFG = {\n",
        "    'NUM_CLASS':34,\n",
        "    'IMG_SIZE':512,\n",
        "    'EPOCHS':10,\n",
        "    'LR':3e-4,\n",
        "    'BATCH_SIZE':32,\n",
        "    'SEED':41\n",
        "}"
      ],
      "metadata": {
        "id": "jTOKC2pvb_Iq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixed Random-Seed"
      ],
      "metadata": {
        "id": "8-UfWnMzcFhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "lPusA5c0cmdq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything(CFG['SEED'])"
      ],
      "metadata": {
        "id": "X0BtnJwWc2MA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "oBZJJfAMc9wH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_boxes_on_image(image_path, annotation_path):\n",
        "    # 이미지 불러오기\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # txt 파일에서 Class ID와 Bounding Box 정보 읽기\n",
        "    with open(annotation_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        values = list(map(float, line.strip().split(' ')))\n",
        "        class_id = int(values[0])"
      ],
      "metadata": {
        "id": "vXTThGn4dAVK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}